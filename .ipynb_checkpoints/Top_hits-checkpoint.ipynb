{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Classifying Explicit Songs on Spotify From 2010-2019 via K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "library(dplyr)\n",
    "library(RColorBrewer)\n",
    "library(cowplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "### In this study, we will study a data set of Top Hit Spotify Songs from 2000-to 2019, originating from Kaggle. \n",
    "With the digitization of the music industry and the prevalence of streaming services such as Spotify and Apple music comes an increased reliance on algorithms to improve user experience: assortments of music are clustered into niche genres, dozens of playlists are curated and cultivated for each of its hundreds of millions of user every single day, and every single minute detail of a user’s interaction with its content is tracked in order to predict whether or they’ll like a recommended song. Spotify would not be where it is today without its strong predictive algorithms. However, despite its impressive and at times invasive approach to algorithms, one important aspect of a song’s metrics is notably absent from its classification systems: explicitness. \n",
    "   \n",
    "   Currently, the onus of classifying music as explicit is placed on the rights-holders, or those who upload music to [Spotify](https://support.spotify.com/us/article/explicit-content/) (Spotify, n.d.). However, because a majority of the most popular music on the streaming service is marked as not explicit, rights holders may not actually be incentivised to properly label their music truthly. It appears that when explicit music fails to be flagged on the part of the rights-holders, it is the responsibility of the listeners to notify spotify; at no point is Spotify accountable in ensuring that potentially harmful content doesn't accidentally fall into the ears of those who are not fit to listen to it. As such, it’s rather surprising that a music-streaming service as large and almost ubiquitous as spotify has yet to develop a classification system that automatically flags music as explicit. \n",
    "    \n",
    "    \n",
    "   Our project plans to fill this very blatant oversight in Spotify’s algorithm by answering the question: is it possible for a song on Spotify to be classified as explicit or non-explicit? To answer this question, we plan to design and implement a k-nearest neighbour classification system with 5-fold cross-validation using the data set [Top Hit Spotify Songs from 2000-to 2019](https://www.kaggle.com/datasets/paradisejoy/top-hits-spotify-from-20002019) (see Koverha, 2022), originating from Kaggle. The title is relatively self explanatory as the data looks at the most popular songs released from each year over the course of twenty years. Furthermore, the data is organized into 18 columns, each of which describes the track and its quality. After exploring the data and deciding on adequate predictor variables, we were able to run the algorithm and properly classify whether or not a song was explicit with 82% accuracy, which can goes to show how simple it would be for Spotify to develop an explicitness classification system in order to improve its user experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read + clean + wrangle data ----------------------------------------------------\n",
    "single_genre <- c('country', 'latin', 'Dance/Electronic', 'Folk/Acoustic',\n",
    "'pop', 'rock','hip hop','R&B','metal','jazz','blues','classical','World/Traditional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "song <- read_csv('https://raw.githubusercontent.com/nicolelassetter/DSCI100-project-g28/main/songs_normalize.csv') %>%\n",
    "    mutate(genre <- as_factor(genre))%>%\n",
    "    filter(genre %in% single_genre)\n",
    "\n",
    "head(song) \n",
    "paste(\"Table 1. Small Preview of Data Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the row of missing data to see if we need to tidy our data, and the result is zero.\n",
    "zero <- sum(anyNA(song))\n",
    "\n",
    "# Table1 : count how many explicit vs non-explict are present to see if we need to balance the data prior training to avoid bias\n",
    "n_explicit <- song %>%\n",
    "    group_by(explicit) %>%\n",
    "    summarize(n = n()) %>%\n",
    "    mutate(percent = 100*n/nrow(song))\n",
    "\n",
    "n_explicit\n",
    "paste('Table 2: How Many in Count and Percentage of Explicit vs Non-Explicit Songs Present in Entire Dataset')\n",
    "paste('The data is still consider balance (74% non-explicit, and 26% explicit), no balancing is required. Furthermore, the majority classifer here is estimated to be 73.9255%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Methods\n",
    "\n",
    "For the sake of the project, we will only use songs with a single genre. \n",
    "\n",
    "Data analysis will be conducted on Jupyter notebook using R. We will use the tidyverse, repr, dplyr, RColorBrewer and themis libraries as they contain the functions required for our calculations and visualizations. Our primary method is classification using K-nearest neighbours (KNN). We mostly based our model from [Data Science: A First Introduction](https://datasciencebook.ca/) (Timbers et al., 2022) and accessed our data from Kaggle (Koverha, 2022). To begin, we will create a training and test data set and use only the training data for the preprocessing/preliminary steps. We split our data set so that 75% of the original data set ends up in the training set, and 25% would be in the test set(using the function initial_split). To increase the readability of the 18 columns, we wil only keep the classifier and the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "# split data to Training + Testing Data ---------------------------------------------\n",
    "song_split <- initial_split(song, prop = 0.75, strata = explicit)\n",
    "song_train <- training(song_split)\n",
    "track_test <- testing(song_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis\n",
    "\n",
    "The genre is plotted into bar graphs to visualize the genre distribution of our training data. Next, scatter plots are used to determine the predictors by looking for relationships. The following step is plotting numerous graphs using our training data with explicit as our classifier to discover relationships. \n",
    "\n",
    "We found that speechiness, energy, danceability and genre had a sort of grouped relationship to explicitness through plotting, and the others did not have a relation. However, genre was not used as a predictor because it consist of categorical values, which does not have a distance metric that is suitable a KNN classification.\n",
    "\n",
    "Hence, the remaining columns needed for the KNN classifier are as follows:\n",
    "\n",
    "1. *explicit*: The song or music video contains content that is considered offensive or inappropriate for children. (either TRUE = Explicit, or FALSE = Non-explicit)\n",
    "2. *speechiness*: Measure from 0.0 to 1.0 of the presence of spoken words. The closer the song is near 1.0, the more words has.\n",
    "3. *energy*: Measure from 0.0 to 1.0, a perceptual measure of intensity and activity.\n",
    "4. *danceability*: How suitable the track is for dancing based on tempo, rhythm stability, beat strength, and overall regularity. 0 = least danceable, 1.0 = most danceable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots that shows little to no relationship to explicitness, put here to show that we did all the exploration, but since there are \n",
    "## too many graphs, we did not show all of them.\n",
    "p00 <- ggplot(song_train,aes(x = popularity,color = explicit))+geom_bar()+scale_fill_brewer(palette = \"Set1\")\n",
    "p01 <- ggplot(song_train,aes(x = year,color = explicit))+geom_bar()+scale_fill_brewer(palette = \"Set1\")\n",
    "p02 <- ggplot(song_train,aes(x = energy ,color = explicit))+geom_bar()+scale_fill_brewer(palette = \"Set1\")\n",
    "p03 <- ggplot(song_train,aes(x = loudness,color = explicit))+geom_bar()+scale_fill_brewer(palette = \"Set1\")\n",
    "p04 <- ggplot(song_train,aes(x = mode ,color = explicit))+geom_bar()+scale_fill_brewer(palette = \"Set1\")\n",
    "p05 <- ggplot(song_train,aes(x = valence ,color = explicit))+geom_histogram()\n",
    "p06 <- ggplot(song_train,aes(x = danceability ,color = explicit))+geom_histogram()\n",
    "p07 <- ggplot(song_train,aes(x = popularity ,color = explicit))+geom_histogram()\n",
    "p08 <- ggplot(song_train,aes(x = key ,color = explicit))+geom_histogram()\n",
    "p09 <- ggplot(song_train,aes(x = loudness ,color = explicit))+geom_histogram()\n",
    "p10 <- ggplot(song_train,aes(x = acousticness ,color = explicit))+geom_histogram()\n",
    "p11 <- ggplot(song_train,aes(x = instrumentalness ,color = explicit))+geom_histogram()\n",
    "p12 <- ggplot(song_train,aes(x = liveness ,color = explicit))+geom_histogram()\n",
    "p13 <- ggplot(song_train,aes(x = valence ,color = explicit))+geom_histogram()\n",
    "p14 <- ggplot(song_train,aes(x = tempo ,color = explicit))+geom_histogram()\n",
    "p15 <- ggplot(song_train,aes(x = genre ,color = explicit))+geom_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using training data: visualise data to find possible predictors relevant for analysis ----\n",
    "\n",
    "# Bar: genre vs count (Number of Songs Total)\n",
    "n_genre_table_training <- song_train %>%\n",
    "    group_by(genre, explicit) %>%\n",
    "    summarize(n = n()) \n",
    "\n",
    "plot1 <- n_genre_table_training %>%\n",
    "    ggplot(aes(x = genre, fill = explicit, y = n)) +\n",
    "    geom_bar(stat = 'identity') +\n",
    "    labs(x = \"Single Song Genres\", y = 'Number of Songs Total', fill = \"Explicit Label\") +\n",
    "    ggtitle('Figure 1. Single Song Genres vs Number of Songs Total Colored by Explicit') +\n",
    "    theme(plot.title = element_text(hjust = 0.5), text = element_text(size = 15)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "    Different Genre seems to have different ratios of non-explict to explict songs.\")\n",
    "\n",
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: Speechiness vs Energy Colored and Shaped by Explicit\n",
    "plot2 <- song_train %>%\n",
    "    ggplot(aes(x = energy, y = speechiness, colour = explicit, shape = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = \"Energy (Scale from 0-1)\", y = 'Speechiness (Scale from 0-1)', shape = \"Explicit Labels\", color = \"Explicit Labels\") +\n",
    "    ggtitle('Figure 2. Speechiness vs Energy Colored and Shaped by Explicit') +\n",
    "    theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 15)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \" For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "There seems to be clustering of explict and non-explict songs between energy of 0.75-1 and speechiness between 0.0 to 0.1,\n",
    "but explict songs are more spread out to a further range of speechiness.\")\n",
    "plot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: Speechiness vs Danceability Colored and Shaped by Explicit\n",
    "plot3 <- song_train %>%\n",
    "    ggplot(aes(x = danceability, y = speechiness, colour = explicit, shape = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = \"Danceability (Scale from 0-1)\", y = 'Speechiness (Scale from 0-1)', shape = \"Explicit Labels\", color = \"Explicit Labels\") +\n",
    "    ggtitle('Figure 3. Speechiness vs Danceability Colored and Shaped by Explicit') +\n",
    "    theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 15)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit. Explict and non-explict songs are clustered differently in this graph. Explict songs\n",
    "    are more spread out to a further range of speechiness, and has a larger range of danceability compare to non-explict songs.\") \n",
    "plot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter : Energy vs Danceability Colored and Shaped by Explicit\n",
    "plot4 <- song_train %>%\n",
    "    ggplot(aes(x = danceability, y = energy, colour = explicit, shape = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = \"Danceability (Scale from 0-1)\", y = 'Energy (Scale from 0-1)', shape = \"Explicit Labels\", color = \"Explicit Labels\") +\n",
    "    ggtitle('Figure 4. Energy vs Danceability Colored and Shaped by Explicit') +\n",
    "    theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 15)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit. Explict and non-explict songs are clustered differently in this graph. \n",
    " Explict songs are more spread out to a further range of speechiness, and non-explict songs \n",
    "are more spread out to a further range of danceability.\")\n",
    "plot4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the whole training data\n",
    "summary(song_train)\n",
    "paste('Table 3: Statistical Summaries of the Entire Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise only training data info that we will we using in our classifier into tables ----------------------------------------\n",
    "mean_table_training <- song_train %>%\n",
    "    select(speechiness, energy, danceability) %>%\n",
    "    map_df(mean)\n",
    "\n",
    "mean_table_training\n",
    "paste('Table 4. Arithmetic Means of Speechiness, Energy, and Danceability Values of the Training Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "\n",
    "The first step of this analysis is selecting the optimal K value for our K-nearest-neighbours (KNN) calculations. Analysis begins with performing a cross-validation calculation using vfold, where the overall training data is split into C evenly sized chunks in order to perform a 5-fold cross-validation. Then cross-validation is run on each train/validation split. This reduces the influence of any one (un)lucky validation set on the estimate. The steps follow below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "# Perform the data analysis -----------------------------------------------------------------------------------\n",
    "\n",
    "# select only the columns that contains the response variable + predictors we will use\n",
    "songs <- song %>%\n",
    "    select(explicit, speechiness, danceability, energy) %>%\n",
    "    mutate(explicit = as_factor(explicit))\n",
    "\n",
    "# split data to Training + Testing data \n",
    "songs_split <- initial_split(songs, prop = 0.75, strata = explicit)\n",
    "songs_train <- training(songs_split)\n",
    "tracks_test <- testing(songs_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a recipe that specifies our class label (explicit) and our predictors (the rest of our predictors). We use our training data, as we don't want our testing data to \"see light\" yet. We also perform the preprocessing steps, passing the training data as the data argument in the recipe. Because we are looking for K, we say neighbors = tune() instead of a number value. This includes scaling all predictors (step_scale and step_center) to ensure they have a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "\n",
    "songs_recipe <- recipe(explicit ~ speechiness + danceability + energy, data = songs_train) %>%\n",
    "    step_scale(all_predictors()) %>%\n",
    "    step_center(all_predictors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "We then add the recipe and model specification to a workflow and use the tune_grid function to estimate the classifier’s accuracy over the training/validation splits. Collect_metrics is used to aggregate the mean and standard error of the classifier’s validation accuracy across the folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "songs_vfold <- vfold_cv(songs_train, v = 5, strata = explicit)\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 10, by = 1))\n",
    "\n",
    "knn_results <- workflow() %>%\n",
    "    add_recipe(songs_recipe) %>%\n",
    "    add_model(knn_tune) %>%\n",
    "    tune_grid(resamples = songs_vfold, grid = k_vals) %>%\n",
    "    collect_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- knn_results %>%\n",
    "     filter(.metric == 'accuracy')\n",
    "\n",
    "print(accuracies)\n",
    "paste(\"Table 5. Validation Accuracy Across the Folds of the Classifier Over the Training/Validation Splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier training and cross-validation is now complete! Now, we plot our filtered knn_results to visualize the accuracy across different values of K. The K value we chose is K=10 because from the plot, we can see this has the highest accuracy and does not change much when we change K to a nearby value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "\n",
    "\n",
    "cross_val_plot <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "    geom_point() +\n",
    "    geom_line() +\n",
    "    labs(x = 'Neighbors', y = 'Accuracy Estimate') +\n",
    "    theme(text = element_text(size = 20)) +\n",
    "    scale_x_continuous(breaks = seq(0, 30)) +\n",
    "    ggtitle( \"Figure 5. Estimated Accuracy vs Neighbors\") +\n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"From K values 1 to 10, K = 10 is observed to have the highest estimated accuracy.\")\n",
    "\n",
    "print(cross_val_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, a new model specification is made for our chosen K = 10 and the classifier is retrained using the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build/train the model \n",
    "knn_spec_2 <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 10) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "songs_fit <- workflow() %>%\n",
    "             add_recipe(songs_recipe) %>%\n",
    "             add_model(knn_spec_2) %>%\n",
    "            fit(data = tracks_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    " \n",
    "Finally, we evaluate the estimated accuracy and predict with our test data. Below are the visualizations of the performed analysis. The first is a plot of the confusion matrix distributions as a bar graph. The second is a graph summarizing the data analysis findings. The third, fourth, and fifth plots compare different variables shaped by Explicit with actual and predicted graphs side by side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model accuracy\n",
    "songs_predictions <- predict(songs_fit, tracks_test) %>%\n",
    "                        bind_cols(tracks_test)\n",
    "\n",
    "accuracy_on_test <- songs_predictions %>% \n",
    "                        metrics(truth = explicit, estimate = .pred_class) %>%\n",
    "                        filter(.metric == \"accuracy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Table 6: Statistics Information About The Accuracy of the Classfier on Testing Set')\n",
    "accuracy_on_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "songs_conf_mat <- songs_predictions %>%\n",
    "                        conf_mat(truth = explicit, estimate = .pred_class) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste('Table7: Confusion Matrix of The Classifier on the Testing Set')\n",
    "songs_conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the analysis ----------------------------------------------------------------------------\n",
    "\n",
    "#bar graph of confusion matrix\n",
    "\n",
    "mat_graph <- songs_predictions %>%\n",
    "    group_by(explicit)%>%\n",
    "    ggplot(aes(x = explicit, fill = .pred_class))+\n",
    "    geom_bar()+\n",
    "    labs(x = \"Explicity\", y = 'Number of Songs', fill = \"Predicted Label \\n By Classifier\" ) +\n",
    "    ggtitle('Figure 6. Bar Graph of Confusion Matrix filled By \\n Predicted Value predicted by KNN Classifier (K = 10)') +\n",
    "    theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 15)) +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "The classifier accurately labelled 23 TRUE and 120 FALSE observations.\n",
    "However, 22 truly TRUE and 9 truly FALSE observations were mislabeled. \") \n",
    "mat_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table with best K, variables, accuracy\n",
    "summary_of_analysis = matrix(c('Explicit', 'Speechiness, danceability, energy', 'K = 10', '81.7 %'), ncol = 1, byrow = TRUE) \n",
    "\n",
    "rownames(summary_of_analysis) <- c('Response variable', 'Predictors used', 'Optimal K', \"Classifier's estimated accuracy on test data\")\n",
    "colnames(summary_of_analysis) <- c('Findings')\n",
    "\n",
    "analysis <- as.data.frame(summary_of_analysis) \n",
    "\n",
    "analysis\n",
    "paste('Table 7. Summary of the Key Information of the Built Classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Speechiness vs Energy Colored and Shaped by Explicit with Actual and Predicted Graphs Side By Side\n",
    "\n",
    "correct_E_vs_S_plot <- ggplot(songs_predictions, aes(x = energy, y = speechiness, color = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Energy(standardized)', y = 'Speechiness (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Actual:') +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "The model has a lower accuracy on predicting explicit songs that has high \n",
    "energy and low speechiness.\")\n",
    "\n",
    "predict_E_vs_S_plot <- ggplot(songs_predictions, aes(x = energy, y = speechiness, color = .pred_class)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Energy(standardized)', y = 'Speechiness (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Predicted:') \n",
    "\n",
    "E_vs_S_plot <- plot_grid(correct_E_vs_S_plot, predict_E_vs_S_plot, ncol = 2, NULL)\n",
    "\n",
    "E_vs_S_title <- ggdraw() + \n",
    "    draw_label(\"Figure 7. Standardized Speechiness vs Energy Colored and Shaped by Explicit of Test Data, \\n \n",
    "    with Correctly labelled and Predicted labels Graphs Side By Side\",\n",
    "    fontface = 'bold', x = 0, hjust = 0, size = 14, lineheight = 0.7) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 7)) \n",
    "\n",
    "\n",
    "E_vs_S_plots <- plot_grid(E_vs_S_title, E_vs_S_plot, ncol = 1,rel_heights = c(0.1, 1)) \n",
    "\n",
    "E_vs_S_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Speechiness vs Danceablity Colored and Shaped by Explicit with Actual and Predicted Graphs Side By Side\n",
    "\n",
    "correct_D_vs_S_plot <- ggplot(songs_predictions, aes(x = danceability, y = speechiness, color = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Danceability(standardized)', y = 'Speechiness (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Actual:') +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "The model has a low accuracy on predicting explicit \n",
    "songs that has danceability in the range of 0.4-0.8, and speechiness of around 0.15.\")\n",
    "\n",
    "\n",
    "predict_D_vs_S_plot <- ggplot(songs_predictions, aes(x = danceability, y = speechiness, color = .pred_class)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Danceability(standardized)', y = 'Speechiness (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Predicted:') \n",
    "\n",
    "D_vs_S_plot <- plot_grid(correct_D_vs_S_plot, predict_D_vs_S_plot, ncol = 2, NULL)\n",
    "\n",
    "D_vs_S_title <- ggdraw() + \n",
    "    draw_label(\"Figure 8. Standardized Speechiness vs Danceablity Colored and Shaped by Explicit of Test Data, \\n \n",
    "    with Correctly labelled and Predicted labels Graphs Side By Side\",\n",
    "    fontface = 'bold', x = 0, hjust = 0, size = 14, lineheight = 0.7) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 7))\n",
    "\n",
    "D_vs_S_plots <- plot_grid(D_vs_S_title, D_vs_S_plot, ncol = 1,rel_heights = c(0.1, 1))\n",
    "\n",
    "D_vs_S_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Energy vs Danceablity Colored and Shaped by Explicit with Actual and Predicted Graphs Side By Side\n",
    "\n",
    "correct_D_vs_E_plot <- ggplot(songs_predictions, aes(x = danceability, y = energy, color = explicit)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Energy(standardized)', y = 'Danceability (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Actual:') +\n",
    "    theme(plot.caption.position = \"plot\", plot.caption = element_text(hjust = 0)) +\n",
    "    labs(caption = \"For explicit label, TRUE = Explicit, FALSE = Non-explicit.\n",
    "The model has a low accuracy on predicting explicit songs that has energy in\n",
    "the range of 0.6-1.0, and danceability in the range of 0.75-1.0.\")\n",
    "\n",
    "predict_D_vs_E_plot <- ggplot(songs_predictions, aes(x = danceability, y = energy, color = .pred_class)) +\n",
    "    geom_point() +\n",
    "    labs(x = 'Energy(standardized)', y = 'Danceability (standardized)', color = 'Explicit label') +\n",
    "    theme(plot.title = element_text(hjust = 0),text = element_text(size = 15)) +\n",
    "    ggtitle('Predicted:') \n",
    "\n",
    "D_vs_E_plot <- plot_grid(correct_D_vs_E_plot, predict_D_vs_E_plot, ncol = 2, NULL) \n",
    "\n",
    "D_vs_E_title <- ggdraw() + \n",
    "    draw_label(\"Figure 9. Standardized Energy vs Danceablity Colored and Shaped by Explicit of Test Data, \\n \n",
    "    with Correctly labelled and Predicted labels Graphs Side By Side\",\n",
    "    fontface = 'bold', x = 0, hjust = 0, size = 14, lineheight = 0.7) +\n",
    "    theme(plot.margin = margin(0, 0, 0, 7))\n",
    "\n",
    "D_vs_E_plots <- plot_grid(D_vs_E_title, D_vs_E_plot, ncol = 1,rel_heights = c(0.1, 1)) \n",
    "\n",
    "\n",
    "D_vs_E_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed through Table 5, K = 10 was the most optimal K because it provided the highest estimated accuracy (81.7%) with a low standard error (1.13%). Furthermore, Figure 5 showed that the estimated accuracy changed by only a small amount if we increased or decreased K near K = 10. Moreover, K = 10 did not require an exorbitant computational cost of training. Hence, K = 10 was selected for the classifier.\n",
    "\n",
    "As assessed through Table 6, the estimated accuracy of the built KNN classifier on the test data was 82.18%, which was higher than the estimated accuracy of the majority classifier (73.5%). The confusion matrix showed that the classifier accurately labelled 23 explicit and 120 non-explicit observations (a total of 143 correctly labelled observations). However, 22 truly explicit and 9 truly non-explicit observations were mislabeled (31 total incorrectly labelled observations). \n",
    "\n",
    "Based on this result, we can see that our model had an accuracy of 51% in predicting explicit songs (23 correctly labelled explict songs / 45 total explict songs), and 93% in predicting non-explicit songs (120 correctly labelled non-explict songs / 129 total non-explict songs). This was not a very good result and was unexpected because the percentage difference is very large, meaning that the model did a poor job in predicting explicit songs but a fairly great job in predicting unexplicit songs. In other words, the model tends to favor predicting unexplicit songs more.\n",
    "\n",
    "These findings could lead to spotify potentially developing an algorithm that could properly flag and detect explicit content such that it doesn’t rely on its users to manually flag it themselves. Streamlining user experience should and continues to be one of Spotify’s top priorities and a classification system such as this could be a possible avenue to explore. However, that doesn’t mean that this classification system is perfect either. To reiterate, our algorithm was only ~82% accurate overall. While false positives aren’t too big of an issue, incorrectly classifying explicit songs as non explicit will have unintended consequences if actually applied by the music streaming platform, especially since our classifier was only able to accurately classify explicit songs 51% of the time.\n",
    "\n",
    "One of the largest limiting factors in our data analysis is the role that genre played in classifying the data. In order to tidy the data set, we had to only filter for songs that only had one assigned genre, ultimately leaving out a notable amount of music that could have changed the results of our classifier. Furthermore, there’s also the fact that a majority of the explicit music was largely confined to one specific genre: hip hop. Because we couldn’t use genre as a KNN predictor due to the fact that it’s a factor and not a numeric value, what could’ve been the largest predictor in explicitness was left out of the classification system, which could explain why our algorithm did such a relatively poor job of classifying explicit music. \n",
    "\n",
    "On another methodological limitation, because explicitness is a concept that is almost entirely dependent on the words of a song and less so on the musical elements that make up the rest of the song, it would be important to consider whether or not we looked at the right observations related to the data. This project opens up the possibility to build a classifying system using [Bagging and AdaBoos](https://doi.org/10.1109/bigcomp.2018.00085) that uses the lyrics themselves as the predictors (Chin et al., 2018) as that is ultimately one of if not the most important variable when determining explicitness, though this would require a completely different data set to be analyzed. Considering that Spotify only [recently](https://techcrunch.com/2021/11/18/spotify-finally-rolls-out-real-time-lyrics-to-global-users/) added lyrics to most of its discography (Perez, 2021), this project would need to take some time to develop. To circle back to our original data set, we could potentially extend the scope of our project to include genre as a factor by building a clustering system on the rest of the variables to see if it’s able to properly predict the genre of a song.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Work Cited*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chin, H., Kim, J., Kim, Y., Shin, J., & Yi, M. Y. (2018). Explicit content detection in music lyrics using machine learning. 2018 IEEE International Conference on Big Data and Smart Computing (BigComp). https://doi.org/10.1109/bigcomp.2018.00085\n",
    "\n",
    "Koverha, M. (2022, May 31). Top hits spotify from 2000-2019. Kaggle. Retrieved June 23, 2022, from https://www.kaggle.com/datasets/paradisejoy/top-hits-spotify-from-20002019\n",
    "\n",
    "\n",
    "Perez, S. (2021, November 18). Spotify finally rolls out real-time lyrics to global users. TechCrunch. Retrieved June 23, 2022, from https://techcrunch.com/2021/11/18/spotify-finally-rolls-out-real-time-lyrics-to-global-users/\n",
    "\n",
    "Explicit content. Spotify. (n.d.). Retrieved June 23, 2022, from https://support.spotify.com/us/article/explicit-content/\n",
    "\n",
    "Timbers, T., Campbell, J., Lee, M., & Peng, R. D. (2022, March 2). Data science. Data Science: A First Introduction. Retrieved June 23, 2022, from https://datasciencebook.ca/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
